{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from legacy_code_assistant.knowledge_base.knowledge_builder import KnowledgeBaseBuilder\n",
    "from legacy_code_assistant.knowledge_base.knowledge_builder import CodeAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path() / '..' / '..' / 'Django-School-Management-System'\n",
    "# path = Path() / '..' / 'test_code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = list(path.rglob('**/*.py'))\n",
    "ca = CodeAnalyzer(paths)\n",
    "results = ca.analyze()\n",
    "print(len(results))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df['len'] = df['code'].apply(lambda x: len(x))\n",
    "df = df.sort_values('len', ascending=False)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Generating docstrings / descriptions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# get credentials from yaml\n",
    "# credentialsy sa wrzucone na discordzie\n",
    "\n",
    "with open(\"credentials.yaml\", \"r\") as f:\n",
    "    credentials = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = credentials['AZURE_OPENAI_ENDPOINT']\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = credentials['AZURE_OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain.prompts import ChatMessagePromptTemplate, ChatPromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_deployment=credentials['Deployment_completion'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docstringable = df.loc[df['type'] != 'module']\n",
    "print(len(df_docstringable), '/', len(df))\n",
    "df_docstringable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docstringable.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "Given the code of the {type} below, write a docstring for it.\n",
    "Do not write anything other than the docstring, docstring should be the only output.\n",
    "Start your answer with ```python\\n\"\"\"\\n and end it with \"\"\"\\n```\n",
    "\\n\\n{code}\\n\\n\n",
    "'''\n",
    "\n",
    "# prompt_ai = '''\n",
    "# Docstring:\\n\\n\n",
    "# ```python\\n\"\"\"\\n\n",
    "# '''\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "# ai_message = AIMessage(content=prompt_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = df_docstringable.iloc[0]\n",
    "chat_prompt_template.format_prompt(type=example['type'], code=example['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [chat_prompt_template.format_prompt(type=example['type'], code=example['code']) for _, example in df_docstringable.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstrings = []\n",
    "\n",
    "for prompt in tqdm(prompts):\n",
    "    result = model(prompt.to_messages()).content\n",
    "    result = re.sub('^\\n*```\\n*(python)\\n*(\"\"\")?\\n*', '', result)\n",
    "    result = re.sub('\\n*(\"\"\")?\\n*```\\n*$', '', result)\n",
    "    docstrings.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docstringable.loc[:, 'generated_docstring'] = docstrings\n",
    "df_docstringable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('knowledge_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docstringable.to_csv('functions_with_generated_docstrings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Make vectorstore based on code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from legacy_code_assistant.knowledge_base.knowledge_builder import KnowledgeBaseBuilder\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter #-> to splits data to chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbb = KnowledgeBaseBuilder(index_name='code_based_index')\n",
    "kbb.initialize_faiss_based_on_df(df, text_column='code')\n",
    "\n",
    "kbb.search('endpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbb.save_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Make vectorstore based on generated docstrings</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=credentials['Deployment_embeddings'],\n",
    "    openai_api_version=\"2023-05-15\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbb = KnowledgeBaseBuilder(index_name='docstring_based_index', model=embeddings)\n",
    "kbb.initialize_faiss_based_on_df(df, text_column='generated_docstring')\n",
    "\n",
    "kbb.search('giving response to the user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROMPT FOR TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_django_test = \"\"\"from django.test import TestCase\n",
    "\n",
    "from apps.corecode.models import (\n",
    "    AcademicSession,\n",
    "    AcademicTerm,\n",
    "    SiteConfig,\n",
    "    Subject,\n",
    ")\n",
    "\n",
    "\n",
    "class SiteConfigTest(TestCase):\n",
    "    def test_siteconfig(self):\n",
    "        site_config = SiteConfig.objects.create(key=\"akey\", value=\"aname\")\n",
    "        self.assertEqual(str(site_config), \"akey\")\n",
    "\n",
    "\n",
    "class AcademicSessionTest(TestCase):\n",
    "    def test_academicsession(self):\n",
    "        session = AcademicSession.objects.create(\n",
    "            name=\"test session\", current=True)\n",
    "        self.assertEqual(str(session), \"test session\")\n",
    "\n",
    "\n",
    "class AcademicTermTest(TestCase):\n",
    "    def test_academicterm(self):\n",
    "        term = AcademicTerm.objects.create(name=\"test Term\", current=True)\n",
    "        self.assertEqual(str(term), \"test Term\")\n",
    "\n",
    "\n",
    "class SubjectTest(TestCase):\n",
    "    def test_subject(self):\n",
    "        subject = Subject.objects.create(name=\"a_subject\")\n",
    "        self.assertEqual(str(subject), \"a_subject\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_tested = df['code'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('functions_with_generated_docstrings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# get credentials from yaml\n",
    "# credentialsy sa wrzucone na discordzie\n",
    "\n",
    "with open(\"credentials.yaml\", \"r\") as f:\n",
    "    credentials = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = credentials['AZURE_OPENAI_ENDPOINT']\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = credentials['AZURE_OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_deployment=credentials['Deployment_completion'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = HumanMessage(\n",
    "    content=f\"Having {text_django_test} as example test for django. Write me another for this one {to_be_tested}. Remebber to take it slow and focus on step by step approach to the problem. Quality over quantity. In the end merge all  little steps.\"\n",
    ")\n",
    "output = model([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown(output.content))\n",
    "# If you particularly want to display maths, this is more direct:\n",
    "display(Latex('\\phi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluesoft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
